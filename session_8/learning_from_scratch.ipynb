{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9wWaHiVkSogH",
    "outputId": "8434c151-e90c-4a57-eb3e-64fbcbc17a27"
   },
   "outputs": [],
   "source": [
    "import kagglehub  # pip install kagglehub\n",
    "\n",
    "# Downloading dataset from Kaggle\n",
    "# https://www.kaggle.com/datasets/phucthaiv02/butterfly-image-classification\n",
    "path = kagglehub.dataset_download(\"phucthaiv02/butterfly-image-classification\")\n",
    "\n",
    "print(\"Path to dataset files:\", path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4iPMJvXTStk5"
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, models, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rx96CuBNSxDZ"
   },
   "outputs": [],
   "source": [
    "train_csv_file = f\"{path}/Training_set.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cBMXmHqpSxgM",
    "outputId": "79c9fa52-260c-4883-cee1-782b1cc81c50"
   },
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = pd.read_csv(train_csv_file)\n",
    "\n",
    "classes = train_data[\"label\"].unique()\n",
    "\n",
    "# Shuffle and split %20 test %80 train\n",
    "train_data = train_data.sample(frac=0.8).reset_index(drop=True)\n",
    "val_data = train_data.sample(frac=0.2).reset_index(drop=True)\n",
    "len(classes), len(train_data), len(val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "koKq8wO6S5yA"
   },
   "outputs": [],
   "source": [
    "# Create folder for each class\n",
    "for class_ in classes:\n",
    "    os.makedirs(f\"./butterfly_dataset/train/{class_}\", exist_ok=True)\n",
    "\n",
    "for class_ in classes:\n",
    "    os.makedirs(f\"./butterfly_dataset/test/{class_}\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0I3jRQl_TMmM"
   },
   "outputs": [],
   "source": [
    "for index, row in train_data.iterrows():\n",
    "    class_ = row[\"label\"]\n",
    "    filename = row[\"filename\"]\n",
    "    shutil.copy(\n",
    "        f\"{path}/train/{filename}\", f\"./butterfly_dataset/train/{class_}/{filename}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NnWBHgUMVItE"
   },
   "outputs": [],
   "source": [
    "for index, row in val_data.iterrows():\n",
    "    class_ = row[\"label\"]\n",
    "    filename = row[\"filename\"]\n",
    "    shutil.copy(\n",
    "        f\"{path}/train/{filename}\", f\"./butterfly_dataset/test/{class_}/{filename}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KvI3bxkbWde8"
   },
   "outputs": [],
   "source": [
    "train_dir = \"./butterfly_dataset/train/\"\n",
    "val_dir = \"./butterfly_dataset/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aCuQgKpeV2rl"
   },
   "outputs": [],
   "source": [
    "# Image transformations\n",
    "data_transforms = {\n",
    "    \"train\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "    \"val\": transforms.Compose(\n",
    "        [\n",
    "            transforms.Resize((224, 224)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n",
    "        ]\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JiDNSYbTWQlF"
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "image_datasets = {\n",
    "    \"train\": datasets.ImageFolder(train_dir, data_transforms[\"train\"]),\n",
    "    \"val\": datasets.ImageFolder(val_dir, data_transforms[\"val\"]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lSj6dWiDXSUH"
   },
   "outputs": [],
   "source": [
    "# Data loaders\n",
    "dataloaders = {\n",
    "    \"train\": torch.utils.data.DataLoader(\n",
    "        image_datasets[\"train\"], batch_size=32, shuffle=True\n",
    "    ),\n",
    "    \"val\": torch.utils.data.DataLoader(\n",
    "        image_datasets[\"val\"], batch_size=32, shuffle=False\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F-t_663hXcQu",
    "outputId": "a7added6-da13-491f-c099-726c76d2ea23"
   },
   "outputs": [],
   "source": [
    "# Class names\n",
    "class_names = image_datasets[\"train\"].classes\n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "duOMjbTTXlNC",
    "outputId": "80d404ce-c835-406e-fce5-c2f01210d717"
   },
   "outputs": [],
   "source": [
    "# Initializing the device GPU or CPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RsuHcNmSYBLR",
    "outputId": "654178b1-fe66-4aeb-dbff-ac3dc2f80478"
   },
   "outputs": [],
   "source": [
    "# Load ResNet18 model\n",
    "model = models.resnet18(weights=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h5ZjbiM1YFpV"
   },
   "outputs": [],
   "source": [
    "# Freeze all layers\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1WqcbmrXYKLE"
   },
   "outputs": [],
   "source": [
    "# Modify the classifier\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Sequential(\n",
    "    nn.Linear(num_features, 256),\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.4),\n",
    "    nn.Linear(256, 75),  # Multi class classification\n",
    ")\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IEQVLl8MYXif"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.fc.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c0-JD0J5YX75"
   },
   "outputs": [],
   "source": [
    "def train_model(model, dataloaders, criterion, optimizer, num_epochs=10):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "    history = {\"train\": [], \"val\": []}\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        for phase in [\"train\", \"val\"]:\n",
    "            if phase == \"train\":\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()  # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            for inputs, labels in dataloaders[phase]:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Forward pass\n",
    "                with torch.set_grad_enabled(phase == \"train\"):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, labels)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "\n",
    "                    if phase == \"train\":\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # Track loss and accuracy\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(image_datasets[phase])\n",
    "            epoch_acc = running_corrects.double() / len(image_datasets[phase])\n",
    "\n",
    "            print(f\"{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
    "            history[phase].append(epoch_acc)\n",
    "\n",
    "            # Save best model\n",
    "            if phase == \"val\" and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "    print(f\"Best val Acc: {best_acc:.4f}\")\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HdHK-9hla9AE",
    "outputId": "c5c47f01-251c-49e5-9be6-c759ab2abe16"
   },
   "outputs": [],
   "source": [
    "model, history = train_model(model, dataloaders, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "yp7nkE8da_5r",
    "outputId": "8db734a4-6dc3-4a70-b3a7-19c4c8f4c2e5"
   },
   "outputs": [],
   "source": [
    "# Plot the training and validation accuracy:\n",
    "\n",
    "train_acc = [h.item() for h in history[\"train\"]]\n",
    "val_acc = [h.item() for h in history[\"val\"]]\n",
    "\n",
    "plt.plot(train_acc, label=\"Train Accuracy\")\n",
    "plt.plot(val_acc, label=\"Validation Accuracy\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Training and Validation Accuracy\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wnnyEOyecKoH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
