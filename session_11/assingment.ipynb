{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment: Fine-Tuning GPT-2 for Text Generation\n",
    "\n",
    "In this assignment, you are required to implement a solution for fine-tuning a GPT-2 model on a text generation task using the Shakespeare-like dataset (`karpathy/tiny_shakespeare`). The task involves pretraining GPT-2 on this dataset, followed by fine-tuning the model to generate text in the style of Shakespeare.\n",
    "\n",
    "#### Requirements:\n",
    "\n",
    "1. **Load the Dataset**:\n",
    "   - Use the `datasets` library to load the `karpathy/tiny_shakespeare` dataset.\n",
    "   - This dataset contains lines from Shakespeare's works and will be used for training the model.\n",
    "\n",
    "2. **Load and Tokenize the GPT-2 Model**:\n",
    "   - Use the `transformers` library to load the pre-trained GPT-2 model (`gpt2`) and tokenizer.\n",
    "   - Set the padding token to the end-of-sequence (EOS) token, as GPT-2 does not have a dedicated padding token by default.\n",
    "\n",
    "3. **Preprocess the Data**:\n",
    "   - Tokenize the text data. Ensure the tokens are padded and truncated to a fixed length.\n",
    "   - Shift the input tokens by one position to create the labels, which will be used for training the model (i.e., predicting the next token).\n",
    "\n",
    "4. **Define Training Arguments**:\n",
    "   - Specify appropriate training parameters, such as number of epochs, batch size, and learning rate scheduler. Make sure to include logging and evaluation strategies.\n",
    "\n",
    "5. **Training the Model**:\n",
    "   - Fine-tune the GPT-2 model on the tokenized dataset using the `Trainer` API from the `transformers` library.\n",
    "   - Monitor the training process and save the model at specified intervals.\n",
    "\n",
    "6. **Text Generation**:\n",
    "   - After training, generate text using the fine-tuned model.\n",
    "   - Provide a prompt, and allow the model to generate text that continues in the style of Shakespeare.\n",
    "\n",
    "#### Deliverables:\n",
    "- Your solution should include the complete code to train and fine-tune the GPT-2 model.\n",
    "- The output should demonstrate that the model can generate text resembling Shakespeareâ€™s style.\n",
    "\n",
    "#### Notes:\n",
    "- Ensure you handle the model's device management (GPU/CPU).\n",
    "- You may choose to modify hyperparameters like the number of epochs, batch size, and sequence length, but try to keep it reasonable based on your available resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
