{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Serialization?\n",
    "\n",
    "Model serialization is the process of saving a trained machine learning model's state, including its architecture, parameters (weights), and other related information, to a file so it can be reloaded and used later without retraining. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Benefits of Model Serialization?\n",
    "\n",
    "1. **Reusability**: Once trained, models can be saved and reused for inference or further training.\n",
    "2. **Portability**: Saved models can be transferred between systems.\n",
    "3. **Deployment**: Serialized models are used in production for predictions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples in Pytorch\n",
    "In PyTorch, model srializatio is commonly done using `torch.save()` for saving and `torch.load()` for loading models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Define and Train a Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "# Define a simple neural network\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleModel, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 50)\n",
    "        self.fc2 = nn.Linear(50, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc2(torch.relu(self.fc1(x)))\n",
    "\n",
    "\n",
    "# Initialize the model, loss, and optimizer\n",
    "model = SimpleModel()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Dummy training loop\n",
    "for epoch in range(5):  # 5 epochs\n",
    "    # Generate some random data\n",
    "    inputs = torch.randn(64, 10)  # Batch size 64, input size 10\n",
    "    targets = torch.randn(64, 1)  # Batch size 64, output size 1\n",
    "\n",
    "    # Forward pass\n",
    "    outputs = model(inputs)\n",
    "    loss = criterion(outputs, targets)\n",
    "\n",
    "    # Backward pass and optimization\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Save the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 1: Saveing state_dict (recommended method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model's state_dict (recommended method)\n",
    "torch.save(model.state_dict(), \"model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the state_dict into a new model instance\n",
    "loaded_model = SimpleModel()\n",
    "loaded_model.load_state_dict(torch.load(\"model.pth\", weights_only=True))\n",
    "loaded_model.eval()  # Set the model to evaluation mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Method 2: Saveing entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the entire model (less flexible, use with caution)\n",
    "torch.save(model, \"model_full.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the entire model (if saved using torch.save(model))\n",
    "full_model = torch.load(\"model_full.pth\", weights_only=False)\n",
    "full_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Notes**: \n",
    "- Always save and load `state_dict` as it's more flexible, especially when modifying or extending the model architecture.\n",
    "- After loading, set the model to evaluation mode using `.eval()` to deactivate dropout and batch normalization layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Additional Information (Checkpoints)\n",
    "Along with `state_dict`, you can save the optimizer's state or training configurations using a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save checkpoints\n",
    "torch.save(\n",
    "    {\n",
    "        \"model_state_dict\": model.state_dict(),\n",
    "        \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "        \"epoch\": epoch,\n",
    "    },\n",
    "    \"checkpoint.pth\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Checkpoint\n",
    "model = SimpleModel()\n",
    "checkpoint = torch.load(\"checkpoint.pth\", weights_only=True)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "optimizer.load_state_dict(checkpoint[\"optimizer_state_dict\"])\n",
    "start_epoch = checkpoint[\"epoch\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "# Predictions\n",
    "inputs = torch.randn(64, 10)  # 64 Samples, each dimention of 10\n",
    "outputs = model(inputs)\n",
    "outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serialization in PyTorch is simple and effective, ensuring your models are ready for reuse and deployment."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
